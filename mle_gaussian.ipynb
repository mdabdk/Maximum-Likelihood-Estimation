{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maximum Likelihood Estimation for Normal Random Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial demonstrates finding the maximum likelihood estimates of the mean $\\mu$ and the standard deviation $\\sigma$ for a Normal random variable $X$. The probability density function of $X$ is:\n",
    "\n",
    "$$f_X(x;\\mu,\\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\exp\\left({-\\frac{(x-\\mu)^2}{2\\sigma^2}}\\right)$$\n",
    "\n",
    "Suppose that you observe 500 independent and identically distributed (i.i.d) samples of $X$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 500\n",
      "Variance: 8.516828536987305\n",
      "Mean: 2.1617989540100098\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "mu = 2\n",
    "sigma = 3\n",
    "num_samples = 500\n",
    "\n",
    "X = torch.randn((num_samples,),requires_grad = False)\n",
    "X = sigma*X + mu\n",
    "\n",
    "print('Number of samples: {}\\nVariance: {}\\nMean: {}'.format(X.shape[0],*torch.var_mean(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The independence assumption is valid if observing one of the samples does not give you information about the other samples, while the identically distributed assumption makes sense if these observations originated from the same underlying random experiment. Therefore, the dataset $\\mathcal{D}$ is:\n",
    "\n",
    "$$\\mathcal{D} = \\{X = x_1,X = x_2,...,X = x_{500}\\}$$\n",
    "\n",
    "The likelihood function is therefore:\n",
    "\n",
    "$$ p(\\mathcal{D};\\mu,\\sigma^2) = \\prod_{i=1}^{500}f_X(x_i;\\mu_i,\\sigma_{i}^2) = \\prod_{i=1}^{500} \\frac{1}{\\sqrt{2\\pi\\sigma_{i}^2}} \\exp\\left({-\\frac{(x_i-\\mu_i)^2}{2\\sigma_{i}^2}}\\right) $$\n",
    "\n",
    "Since the samples are identically distributed:\n",
    "\n",
    "$$\n",
    "\\mu_1 = \\mu_2 = ... = \\mu_{500} = \\mu \\\\\n",
    "\\sigma_{1}^2 = \\sigma_{2}^2 = ... = \\sigma_{500}^2 = \\sigma^2\n",
    "$$\n",
    "\n",
    "And the log-likelihood function is:\n",
    "\n",
    "\\begin{align}\n",
    "\\ln(p(\\mathcal{D};\\mu,\\sigma^2)) &= \\sum_{i=1}^{500} \\ln\\left(\\frac{1}{\\sqrt{2\\pi\\sigma_{i}^2}}\\right) + \\ln\\left(\\exp\\left({-\\frac{(x_i-\\mu_i)^2}{2\\sigma_{i}^2}}\\right)\\right) \\\\\n",
    "&= -\\left(\\sum_{i=1}^{500} \\ln\\left(\\sqrt{2\\pi\\sigma_{i}^2}\\right) + \\sum_{i=1}^{500} \\frac{(x_i-\\mu_i)^2}{2\\sigma_{i}^2}\\right)\n",
    "\\end{align}\n",
    "\n",
    "Since the samples are i.i.d:\n",
    "\n",
    "$$\n",
    "\\ln(p(\\mathcal{D};\\mu,\\sigma^2)) = -\\left(500 \\ln\\left(\\sqrt{2\\pi\\sigma^2}\\right) + \\frac{1}{2\\sigma^2}\\sum_{i=1}^{500} (x_i-\\mu)^2 \\right)\n",
    "$$\n",
    "\n",
    "The negative of the log-likelihood function can be implemented as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(55309.4961)\n"
     ]
    }
   ],
   "source": [
    "# Negative log-likelihood of X\n",
    "\n",
    "from math import pi\n",
    "\n",
    "# theta[0] = mu, theta[1] = sigma\n",
    "def normal_NLL(X,theta):\n",
    "    first_term = X.shape[0]*torch.log(torch.sqrt(2*pi*torch.pow(theta[1],2)))\n",
    "    second_term = torch.div(1.,2*torch.pow(theta[1],2))*torch.sum(torch.pow(X-theta[0],2))\n",
    "    return (first_term + second_term)\n",
    "\n",
    "theta = torch.randn((2,))\n",
    "NLL = normal_NLL(X,theta)\n",
    "print(NLL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, the maximum likelihood estimates of $\\mu$ and $\\sigma^2$ are:\n",
    "\n",
    "\\begin{equation}\n",
    "\\DeclareMathOperator*{\\argmin}{\\arg\\!\\min}\n",
    "\\hat{\\mu} = \\argmin_{\\mu}{\\left(-\\ln\\left(p\\left(\\mathcal{D};\\mu,\\sigma^2\\right)\\right)\\right)} =  \\argmin_{\\mu}\\sum_{i=1}^{500} \\frac{(x_i-\\mu)^2}{2\\sigma^2}\\\\\n",
    "\\hat{\\sigma}^2 = \\argmin_{\\sigma^2}{\\left(-\\ln\\left(p\\left(\\mathcal{D};\\mu,\\sigma^2\\right)\\right)\\right)} = \\argmin_{\\sigma^2} \\left(\\sum_{i=1}^{500}\\ln\\left(\\sqrt{2\\pi\\sigma^2}\\right) + \\sum_{i=1}^{500} \\frac{(x_i-\\mu)^2}{2\\sigma^2}\\right)\n",
    "\\end{equation}\n",
    "\n",
    "$\\hat{\\mu}$ and $\\hat{\\sigma}^2$ can be computed analytically. First for $\\hat{\\mu}$:\n",
    "\n",
    "$$- \\frac{\\partial\\ln\\left(p\\left(\\mathcal{D};\\mu,\\sigma^2\\right)\\right)}{\\partial\\mu} = \\frac{1}{2\\sigma^2} \\sum_{i=1}^{500} -2(x_i-\\mu) = -\\frac{1}{\\sigma^2} \\sum_{i=1}^{500} x_i-\\mu = 0 $$\n",
    "\n",
    "Solving for $\\mu$:\n",
    "\n",
    "$$\\hat{\\mu} = \\frac{\\sum_{i=1}^{500} x_i}{500}$$\n",
    "\n",
    "Which is just the sample mean. Similarly, for the standard deviation:\n",
    "\n",
    "$$\n",
    "-\\frac{\\partial\\ln\\left(p\\left(\\mathcal{D};\\mu,\\sigma^2\\right)\\right)}{\\partial\\sigma^2} = \\frac{500}{2\\sigma^2} - \\frac{1}{2\\sigma^4} \\sum_{i=1}^{500} (x_i-\\mu)^2 = 0\n",
    "$$\n",
    "\n",
    "Solving for $\\sigma^2$:\n",
    "\n",
    "$$\n",
    "\\hat{\\sigma}^2 = \\frac{1}{500} \\sum_{i=1}^{500} (x_i-\\mu)^2\n",
    "$$\n",
    "\n",
    "Which is just the sample variance. However, this is a biased estimator of the $\\sigma^2$. Instead, the sample variance can be computed as follows:\n",
    "\n",
    "$$\n",
    "\\hat{\\sigma}^2 = \\frac{1}{500-1} \\sum_{i=1}^{500} (x_i-\\mu)^2\n",
    "$$\n",
    "\n",
    "This modification is called [Bessel's correction](https://en.wikipedia.org/wiki/Bessel%27s_correction). The maximum likelihood estimates of $\\mu$ and $\\sigma^2$ can then be computed as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.1618)\n"
     ]
    }
   ],
   "source": [
    "# sample mean\n",
    "\n",
    "mu_hat = torch.sum(X)/X.shape[0]\n",
    "\n",
    "print(mu_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.5168)\n"
     ]
    }
   ],
   "source": [
    "# sample variance\n",
    "\n",
    "sigma_squared_hat = torch.sum(torch.pow(X-mu_hat,2))/(X.shape[0]-1)\n",
    "\n",
    "print(sigma_squared_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, the maximum likelihood estimates of $\\mu$ and $\\sigma^2$ can be computed using gradient descent. Gradient descent is an iterative algorithm based on the following general methodology:\n",
    "1. Guess an initial value for the parameter vector $\\mathbf{\\theta} = (\\mu,\\sigma)$.\n",
    "2. Compute the gradient of the negative log-likeihood function at these initial values of $\\mu$ and $\\sigma$. More precisely, if $\\mathbf{\\theta}_0 = (\\mu_0,\\sigma_0)$ is the initial parameter vector, then compute:\n",
    "\n",
    "$$\n",
    "-\\left.\\frac{\\partial\\ln\\left(p\\left(\\mathcal{D};\\mathbf{\\theta}\\right)\\right)}{\\partial\\mathbf{\\theta}} \\right\\rvert_{\\mathbf{\\theta} = \\mathbf{\\theta}_0}\n",
    "$$\n",
    "\n",
    "Note that the vector $\\mathbf{\\theta} = (\\mu,\\sigma)$ was used here because the individual partial derivatives of the negative log-likelihood function with respect to $\\mu$ and $\\sigma$ can only be used to perform minimization exclusively with respect to $\\mu$ or $\\sigma$ but not both at the same time.\n",
    "\n",
    "3. Use some function:\n",
    "\n",
    "$$\n",
    "\\mathbf{\\theta}_1 = g\\left(\\mathbf{\\theta}_0,-\\left.\\frac{\\partial\\ln\\left(p\\left(\\mathcal{D};\\mathbf{\\theta}\\right)\\right)}{\\partial\\mathbf{\\theta}} \\right\\rvert_{\\mathbf{\\theta} = \\mathbf{\\theta}_0}\\right)\n",
    "$$\n",
    "\n",
    "To choose a new parameter vector $\\mathbf{\\theta}_1$ that minimizes the negative log-likelihood function.\n",
    "\n",
    "4. Repeat steps 1,2, and 3 until convergence.\n",
    "\n",
    "The following explanation for how to choose $g(\\cdot)$ is adapted from [here](https://eli.thegreenplace.net/2016/understanding-gradient-descent/). Consider the simple function $f(x) = x^2$. The value of $f(x)$ decreases when x is negative and increasing, while its value increases when x is positive and increasing. Given an infinitesimally small change $dx$, such that:\n",
    "\n",
    "\\begin{align}\n",
    "f(x)+df(x) &= (x+dx)^2 \\\\\n",
    "f(x)+df(x) &= x^2 + 2x dx + {dx}^2 \\\\\n",
    "x^2 + df(x) &= x^2 + 2x dx \\\\\n",
    "df(x) &= 2x dx \\\\\n",
    "\\frac{df(x)}{dx} &= 2x\n",
    "\\end{align}\n",
    "\n",
    "Suppose that you do not know where the minimum of $f(x)$ is. Let us guess first that the minimum is at $x = -2$. The derivative of $f(x)$ at $x = -2$ is $-4$, which means that an infinitely small increase in $x$, denoted as $dx$, will result in a decrease in $f(x)$ by a factor of 4. Thus, it makes sense to increase $x$ in order to reach the minimum of $f(x)$. In fact, for any convex function $f(x)$, the negative of its derivative $\\frac{df(x)}{dx}$ will always \"point\" towards its minimum point. So, it makes sense to make a new guess $x_{new}$ such that:\n",
    "\n",
    "$$\n",
    "x_{new} = x_{old} - \\eta\\left.\\frac{df(x)}{dx}\\right\\rvert_{x = x_{old}}\n",
    "$$\n",
    "\n",
    "Where $\\eta$ is a small constant called the _learning rate_ that controls the magnitude of $\\frac{df(x)}{dx}$ and thus controls the magnitude of each change of $x$.\n",
    "\n",
    "For multivariate functions, such as $f(\\mathbf{\\theta})$ where $\\mathbf{\\theta} = (x,y,z)$, it can be shown that its gradient $\\nabla_{\\mathbf{\\theta}}f(\\mathbf{\\theta})$ points in the direction of steepest ascent, and so its negative points in the direction of steepest ascent. Therefore, for multivariate functions, the update rule becomes:\n",
    "\n",
    "$$\n",
    "\\mathbf{\\theta}_{new} = \\mathbf{\\theta}_{old} - \\eta \\left.\\nabla_{\\mathbf{\\theta}}f(\\mathbf{\\theta})\\right\\rvert_{\\mathbf{\\theta} = \\mathbf{\\theta}_{old}}\n",
    "$$\n",
    "\n",
    "Therefore, in the case of $\\mu$ and $\\sigma$, the required gradient is:\n",
    "\n",
    "$$\n",
    "\\nabla_{\\mathbf{\\theta}}NLL(\\mathcal{D},\\mathbf{\\theta})\n",
    "$$\n",
    "\n",
    "Where $\\mathbf{\\theta} = (\\mu,\\sigma)$.\n",
    "\n",
    "Gradient descent can be implemented as follows. First, an initial theta is chosen at random, and its gradient is tracked:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 5.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "theta_old = torch.tensor([3.,5.],requires_grad=True)\n",
    "\n",
    "print(theta_old)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the guess for `theta_old` is biased here to ensure that the gradient descent algorithm converges to the correct parameter estimates, since it only converges to a local minimum. If the correct estimates are not important, then the following guess can be optionally used instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.8079, -0.5899], requires_grad=True)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_old = torch.randn((2,),requires_grad = True)\n",
    "\n",
    "print(theta_old)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, a learning rate is chosen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the negative log-likelihood of X is computed for the initial theta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1356.2119, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "NLL = normal_NLL(X,theta_old)\n",
    "\n",
    "print(NLL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient of the negative log-likelihood function with respect to theta is then computed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "NLL.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new value of theta is then computed using the gradient descent update rule:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.9832, 4.9368], grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "theta_new = theta_old - lr*theta_old.grad\n",
    "\n",
    "print(theta_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, this process is repeated until convergence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1e-10\n",
    "\n",
    "while torch.norm(theta_new - theta_old).item() > eps:\n",
    "    theta_old = theta_new.detach().requires_grad_() # copy \n",
    "    NLL = normal_NLL(X,theta_old)\n",
    "    NLL.backward()\n",
    "    theta_new = theta_old - lr*theta_old.grad\n",
    "    theta_old.grad.zero_() # zero gradients accumulated in .grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final estimates of $\\mu$ and $\\sigma^2$ are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum likelihood estimate of mean: 2.1618008613586426\n",
      "Maximum likelihood estimate of variance: 8.499797825891676\n"
     ]
    }
   ],
   "source": [
    "print('Maximum likelihood estimate of mean: {}'.format(theta_new[0].item()))\n",
    "print('Maximum likelihood estimate of variance: {}'.format(theta_new[1].item()**2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
